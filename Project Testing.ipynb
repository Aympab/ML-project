{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "100ab686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel, Matern\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927324bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = pd.read_csv(\"starting_kit/data/protein_train.data\", sep=\" \", header=None)\n",
    "y_data = pd.read_csv(\"starting_kit/data/protein_train.solution\", sep=\" \", header=None)\n",
    "\n",
    "X_test_data = pd.read_csv(\"starting_kit/data/protein_test.data\", sep=\" \", header=None)\n",
    "X_valid_data = pd.read_csv(\"starting_kit/data/protein_valid.data\", sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31de5c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.051</td>\n",
       "      <td>...</td>\n",
       "      <td>8.996</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-2.296</td>\n",
       "      <td>-5.124</td>\n",
       "      <td>4.268</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-4.644</td>\n",
       "      <td>2.697</td>\n",
       "      <td>1.124</td>\n",
       "      <td>2.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.077</td>\n",
       "      <td>...</td>\n",
       "      <td>27.622</td>\n",
       "      <td>2.517</td>\n",
       "      <td>3.343</td>\n",
       "      <td>-19.543</td>\n",
       "      <td>17.150</td>\n",
       "      <td>-11.894</td>\n",
       "      <td>-14.239</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>6.017</td>\n",
       "      <td>8.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.054</td>\n",
       "      <td>...</td>\n",
       "      <td>64.266</td>\n",
       "      <td>11.886</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>-44.047</td>\n",
       "      <td>39.708</td>\n",
       "      <td>-31.910</td>\n",
       "      <td>-37.893</td>\n",
       "      <td>-5.492</td>\n",
       "      <td>11.690</td>\n",
       "      <td>20.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>80.416</td>\n",
       "      <td>21.129</td>\n",
       "      <td>4.508</td>\n",
       "      <td>-55.792</td>\n",
       "      <td>32.963</td>\n",
       "      <td>-26.239</td>\n",
       "      <td>-62.055</td>\n",
       "      <td>-3.766</td>\n",
       "      <td>10.171</td>\n",
       "      <td>20.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>34.747</td>\n",
       "      <td>2.485</td>\n",
       "      <td>-2.486</td>\n",
       "      <td>-25.222</td>\n",
       "      <td>22.287</td>\n",
       "      <td>-13.880</td>\n",
       "      <td>-23.592</td>\n",
       "      <td>5.089</td>\n",
       "      <td>10.324</td>\n",
       "      <td>9.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53113</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>62.061</td>\n",
       "      <td>11.254</td>\n",
       "      <td>-11.063</td>\n",
       "      <td>-41.835</td>\n",
       "      <td>41.653</td>\n",
       "      <td>-17.432</td>\n",
       "      <td>-38.004</td>\n",
       "      <td>5.285</td>\n",
       "      <td>17.813</td>\n",
       "      <td>21.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53114</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>16.781</td>\n",
       "      <td>4.918</td>\n",
       "      <td>0.903</td>\n",
       "      <td>-3.647</td>\n",
       "      <td>8.940</td>\n",
       "      <td>-8.705</td>\n",
       "      <td>-6.220</td>\n",
       "      <td>-5.351</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>6.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53115</th>\n",
       "      <td>0.109</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.064</td>\n",
       "      <td>...</td>\n",
       "      <td>67.318</td>\n",
       "      <td>13.292</td>\n",
       "      <td>-8.059</td>\n",
       "      <td>-52.886</td>\n",
       "      <td>39.761</td>\n",
       "      <td>-20.426</td>\n",
       "      <td>-41.685</td>\n",
       "      <td>2.594</td>\n",
       "      <td>15.800</td>\n",
       "      <td>22.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53116</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.028</td>\n",
       "      <td>...</td>\n",
       "      <td>24.277</td>\n",
       "      <td>5.070</td>\n",
       "      <td>2.114</td>\n",
       "      <td>-13.588</td>\n",
       "      <td>12.932</td>\n",
       "      <td>-11.197</td>\n",
       "      <td>-19.363</td>\n",
       "      <td>-2.118</td>\n",
       "      <td>1.972</td>\n",
       "      <td>5.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53117</th>\n",
       "      <td>0.092</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.032</td>\n",
       "      <td>...</td>\n",
       "      <td>36.250</td>\n",
       "      <td>7.366</td>\n",
       "      <td>-1.754</td>\n",
       "      <td>-26.369</td>\n",
       "      <td>22.233</td>\n",
       "      <td>-13.002</td>\n",
       "      <td>-25.810</td>\n",
       "      <td>5.944</td>\n",
       "      <td>6.134</td>\n",
       "      <td>6.631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53118 rows Ã— 952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9    \\\n",
       "0      0.068  0.068  0.085  0.068  0.000  0.051  0.017  0.000  0.051  0.051   \n",
       "1      0.094  0.069  0.064  0.099  0.039  0.073  0.043  0.013  0.034  0.077   \n",
       "2      0.067  0.062  0.054  0.132  0.045  0.060  0.038  0.018  0.018  0.054   \n",
       "3      0.063  0.056  0.071  0.162  0.036  0.058  0.062  0.022  0.036  0.036   \n",
       "4      0.081  0.085  0.078  0.104  0.030  0.078  0.033  0.000  0.019  0.074   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "53113  0.088  0.095  0.067  0.091  0.047  0.091  0.030  0.000  0.032  0.060   \n",
       "53114  0.054  0.034  0.041  0.095  0.054  0.027  0.034  0.041  0.020  0.074   \n",
       "53115  0.109  0.088  0.076  0.086  0.035  0.086  0.033  0.002  0.029  0.064   \n",
       "53116  0.074  0.047  0.098  0.195  0.070  0.051  0.060  0.023  0.019  0.028   \n",
       "53117  0.092  0.060  0.074  0.074  0.049  0.071  0.046  0.011  0.039  0.032   \n",
       "\n",
       "       ...     942     943     944     945     946     947     948    949  \\\n",
       "0      ...   8.996  -0.156  -2.296  -5.124   4.268  -0.248  -4.644  2.697   \n",
       "1      ...  27.622   2.517   3.343 -19.543  17.150 -11.894 -14.239 -0.212   \n",
       "2      ...  64.266  11.886  -0.480 -44.047  39.708 -31.910 -37.893 -5.492   \n",
       "3      ...  80.416  21.129   4.508 -55.792  32.963 -26.239 -62.055 -3.766   \n",
       "4      ...  34.747   2.485  -2.486 -25.222  22.287 -13.880 -23.592  5.089   \n",
       "...    ...     ...     ...     ...     ...     ...     ...     ...    ...   \n",
       "53113  ...  62.061  11.254 -11.063 -41.835  41.653 -17.432 -38.004  5.285   \n",
       "53114  ...  16.781   4.918   0.903  -3.647   8.940  -8.705  -6.220 -5.351   \n",
       "53115  ...  67.318  13.292  -8.059 -52.886  39.761 -20.426 -41.685  2.594   \n",
       "53116  ...  24.277   5.070   2.114 -13.588  12.932 -11.197 -19.363 -2.118   \n",
       "53117  ...  36.250   7.366  -1.754 -26.369  22.233 -13.002 -25.810  5.944   \n",
       "\n",
       "          950     951  \n",
       "0       1.124   2.635  \n",
       "1       6.017   8.955  \n",
       "2      11.690  20.689  \n",
       "3      10.171  20.835  \n",
       "4      10.324   9.218  \n",
       "...       ...     ...  \n",
       "53113  17.813  21.263  \n",
       "53114  -0.587   6.750  \n",
       "53115  15.800  22.920  \n",
       "53116   1.972   5.346  \n",
       "53117   6.134   6.631  \n",
       "\n",
       "[53118 rows x 952 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb5171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data2 = X_data.iloc[:15].copy()\n",
    "y_data2 = y_data.iloc[:15].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data2, y_data2,random_state=0, test_size=0.2)\n",
    "scaler = RobustScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_scaled = pca.transform(X_train_scaled)\n",
    "X_test_scaled = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b03be6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGboost\n",
    "tuned_parameters = [{'max_depth': [5,10, 15, 20, 25, 30],'learning_rate':[0.001, 0.01, 0.1, 0.5], 'n_estimators': [100,150,200, 250, 300]}]\n",
    "clas = GridSearchCV(xgb.XGBClassifier(), tuned_parameters, cv=4, n_jobs=-1)\n",
    "clas.fit(X_train_scaled, y_train)\n",
    "y_true, y_pred2 = y_test, clas.predict(X_test_scaled)\n",
    "    \n",
    "print('The best hyper-parameters for XGBBoost are: ',clas.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2cb54e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper-parameters for Random Forests are:  {'max_depth': 5, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "tuned_parameters = [{'max_depth': [5,10, 15, 20, 50, 70], 'n_estimators': [10, 25, 50, 100,150, 200, 250]}]\n",
    "clas_rf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=4, n_jobs=-1)\n",
    "clas_rf.fit(X_train_scaled, y_train)\n",
    "y_true, y_pred5 = y_test, clas_rf.predict(X_test_scaled)\n",
    "    \n",
    "print('The best hyper-parameters for Random Forests are: ',clas_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87b0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper-parameters for KNN are:  {'n_neighbors': 1, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "tuned_parameters = [{'n_neighbors': [1,2,3,4,5,10,15,20], 'p': [1,2]}]\n",
    "model = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=4)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print('The best hyper-parameters for KNN are: ', model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57a029e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper-parameters for SVR are:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "tuned_parameters = [{'kernel': ['linear', 'rbf', 'poly'], 'C':[1, 2, 3, 5, 6, 7, 10], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1]}]\n",
    "svm_clas = GridSearchCV(SVC(), tuned_parameters, cv=4, n_jobs=-1)\n",
    "svm_clas.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print('The best hyper-parameters for SVR are: ', svm_clas.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c33531bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31870, 42494]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EDUARD~1.VIT\\AppData\\Local\\Temp/ipykernel_13144/3094757649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtuned_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclas_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclas_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclas_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\projet-ml\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\projet-ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\projet-ml\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [31870, 42494]"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tuned_parameters = [{'max_depth': [1,2,3,4,5,10, 15, 20, 25, 50, 100,200]}]\n",
    "clas_dt = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=4, n_jobs=-1)\n",
    "clas_dt.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print('The optimum max_depth for Decision Tree is: ', clas_dt.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c934dea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyper-parameters for GPR are:  {'kernel': 1**2 * RBF(length_scale=10), 'n_restarts_optimizer': 5}\n"
     ]
    }
   ],
   "source": [
    "# GP\n",
    "kernel1 = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "kernel2 = C() + Matern(length_scale=0.5, nu=3/2) \n",
    "kernel3 = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2)) +  C(1.0, (1e-3, 1e3))* Matern(length_scale=2, nu=3/2)\n",
    "kernel4 = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "tuned_parameters = [{'kernel': [kernel1,kernel2,kernel3,kernel4], \n",
    "                   'n_restarts_optimizer':[5]}]\n",
    "gpclas = GridSearchCV(GaussianProcessClassifier(), tuned_parameters, cv=4, n_jobs=-1)\n",
    "gpclas.fit(X_train_scaled, y_train)\n",
    "    \n",
    "print('The best hyper-parameters for GPR are: ', gpclas.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "169db4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost Classifier :accuracy_score 1.0\n",
      "Decision Tree Classifier :accuracy_score 1.0\n",
      "Random Forests Classifier -accuracy_score: 1.0\n",
      "Logistic Regressor :accuracy_score 1.0\n",
      "KNN Classifier :accuracy_score: 1.0\n",
      "SVR Classifier :accuracy_score: 1.0\n",
      "GP Classifier :accuracy_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgclas = xgb.XGBClassifier(learning_rate=0.001, max_depth=5, n_estimators=100, random_state = 0)\n",
    "xgclas.fit(X_train_scaled, y_train, n_jobs=-1)\n",
    "y_pred1 = xgclas.predict(X_test_scaled)              \n",
    "print('XGBoost Classifier :accuracy_score', accuracy_score(y_test,y_pred1))\n",
    "\n",
    "# Decision Tree\n",
    "clas_dt = DecisionTreeClassifier(random_state=0, max_depth = 4)\n",
    "clas_dt.fit(X_train_scaled,y_train, n_jobs=-1)\n",
    "y_pred2 = clas_dt.predict(X_test_scaled)        # Decision Tree\n",
    "print('Decision Tree Classifier :accuracy_score', accuracy_score(y_test,y_pred2))\n",
    "\n",
    "# Random Forests\n",
    "regr_rf = RandomForestClassifier(max_depth=5, random_state=0, n_estimators=10)\n",
    "regr_rf.fit(X_train_scaled, y_train)\n",
    "y_pred3 = regr_rf.predict(X_test_scaled)           \n",
    "print('Random Forests Classifier -accuracy_score:', accuracy_score(y_test,y_pred3))\n",
    "\n",
    "# Logistic Regression\n",
    "logclas = LogisticRegression()\n",
    "logclas.fit(X_train_scaled, y_train, n_jobs=-1)\n",
    "y_pred4 = logclas.predict(X_test_scaled)           \n",
    "print('Logistic Regressor :accuracy_score', accuracy_score(y_test,y_pred4))\n",
    "\n",
    "# KNN\n",
    "neigh = KNeighborsClassifier(n_neighbors = 2, metric = 'minkowski', p = 1)\n",
    "neigh.fit(X_train_scaled, y_train, n_jobs=-1)\n",
    "y_pred5 = neigh.predict(X_test_scaled) \n",
    "print('KNN Classifier :accuracy_score:', accuracy_score(y_test,y_pred5))\n",
    "\n",
    "# SVM\n",
    "svm_clas = SVC(gamma=1, kernel = 'linear', C=0.0001)\n",
    "svm_clas.fit(X_train_scaled, y_train, n_jobs=-1)\n",
    "y_pred6 = svm_clas.predict(X_test_scaled)     # SVR\n",
    "print('SVR Classifier :accuracy_score:',accuracy_score(y_test,y_pred6))\n",
    "\n",
    "# GPR\n",
    "gp = GaussianProcessClassifier(kernel=kernel1, n_restarts_optimizer=5)\n",
    "gp.fit(X_train_scaled, y_train, n_jobs=-1)\n",
    "y_pred8 = gp.predict(X_test_scaled)         \n",
    "print('GP Classifier :accuracy_score:', accuracy_score(y_test,y_pred8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af0fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
